import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tempfile
import pandas as pd
import threading
import queue
import time

# --- é é¢é…ç½® ---
st.set_page_config(page_title="Barbell Tracker Pro V2", layout="wide") 

# è‡ªå®šç¾© CSS ä»¥å„ªåŒ–æ‰‹æ©Ÿé¡¯ç¤º
st.markdown("""
    <style>
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .stMetric { background-color: #f0f2f6; padding: 10px; border-radius: 8px; }
    /* Mobile Touch Fix: Prevent scrolling when touching canvas */
    iframe[title="streamlit_drawable_canvas.st_canvas"] {
        touch-action: none; 
    }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‹ï¸ æ éˆ´é€Ÿåº¦åˆ†æ V2 (Web)")
st.caption("ç§»æ¤è‡ª Desktop Pro ç‰ˆ | æ”¯æ´ Reps åµæ¸¬èˆ‡é™å¹…åˆ†æ")
st.markdown("---")

# --- è¼”åŠ©å‡½æ•¸: å¹³æ»‘è™•ç† ---
def smooth_data(data, window_size):
    if len(data) < window_size: return data
    window = np.hanning(window_size)
    window = window / window.sum()
    return np.convolve(data, window, mode='same')

class ThreadedVideoReader:
    def __init__(self, path, start_frame, end_frame, scale_factor, rotation_code=None):
        self.path = path
        self.start_frame = start_frame
        self.end_frame = end_frame
        self.scale_factor = scale_factor
        self.rotation_code = rotation_code
        self.queue = queue.Queue(maxsize=1024) # Buffer size increased for performance
        self.stopped = False
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
    
    def start(self):
        self.thread.start()
        return self

    def update(self):
        cap = cv2.VideoCapture(self.path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
        current_idx = self.start_frame

        while current_idx < self.end_frame:
            if self.stopped:
                break
            
            if not self.queue.full():
                ret, frame = cap.read()
                if not ret:
                    self.stop()
                    break
                
                # Rotation
                if self.rotation_code is not None:
                    frame = cv2.rotate(frame, self.rotation_code)

                # Pre-process in thread
                frame_small = cv2.resize(frame, (0,0), fx=self.scale_factor, fy=self.scale_factor)
                
                self.queue.put((ret, frame_small, current_idx))
                current_idx += 1
            else:
                time.sleep(0.01) # Wait a bit if queue is full

        cap.release()
        self.stopped = True

    def read(self):
        # Return next frame in the queue. 
        # returns (ret, frame, idx) or None if empty/finished
        try:
            return self.queue.get(timeout=1)
        except queue.Empty:
            return None

    def more(self):
        return not self.stopped or not self.queue.empty()

    def stop(self):
        self.stopped = True
        # Drain queue to allow thread to exit if blocked
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except queue.Empty:
                break


# --- 1. ä¸Šå‚³èˆ‡åˆå§‹åŒ– ---
st.header("1. ä¸Šå‚³å½±ç‰‡")
uploaded_file = st.file_uploader("é¸æ“‡å½±ç‰‡æ–‡ä»¶ (MP4/MOV)", type=['mp4', 'mov', 'avi'])

if uploaded_file is not None:
    # ä¿å­˜è‡¨æ™‚æ–‡ä»¶
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name
    
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if np.isnan(fps) or fps < 1: fps = 30
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    # --- Global Settings (Sidebar) ---
    st.sidebar.header("è¨­å®š (Settings)")
    
    # 1. Mobile Optimization
    is_mobile = st.sidebar.checkbox("ğŸ“± æ‰‹æ©Ÿæ¨¡å¼ (Mobile View)", value=True, help="é–‹å•Ÿä»¥ç²å¾—æœ€ä½³æ‰‹æ©Ÿé«”é©—")
    
    # 2. Rotation (Auto Portrait)
    # Get Video Dimensions
    v_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    v_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    st.sidebar.subheader("å½±ç‰‡æ—‹è½‰ (Rotation)")
    auto_portrait = st.sidebar.checkbox("ğŸ”„ è‡ªå‹•è½‰æ­£ (Auto Portrait)", value=True, help="è‹¥å½±ç‰‡ç‚ºæ©«å‘ (å¯¬ > é«˜)ï¼Œè‡ªå‹•æ—‹è½‰ 90 åº¦")
    
    rotation_code = None
    
    if auto_portrait:
        if v_width > v_height:
            rotation_code = cv2.ROTATE_90_CLOCKWISE
            st.sidebar.info(f"å·²è‡ªå‹•æ—‹è½‰ 90 åº¦\n(åŸå§‹: {v_width}x{v_height})")
    else:
        # Manual Rotation
        rotate_option = st.sidebar.selectbox(
            "æ‰‹å‹•èª¿æ•´ (Manual)",
            options=[0, 90, 180, 270],
            index=0,
            help="è‹¥è‡ªå‹•è½‰æ­£ä¸æ­£ç¢ºï¼Œè«‹é—œé–‰è‡ªå‹•æ¨¡å¼ä¸¦æ‰‹å‹•é¸æ“‡"
        )
        
        if rotate_option == 90:
            rotation_code = cv2.ROTATE_90_CLOCKWISE
        elif rotate_option == 180:
            rotation_code = cv2.ROTATE_180
        elif rotate_option == 270:
            rotation_code = cv2.ROTATE_90_COUNTERCLOCKWISE
            
    # 3. Performance / Speed Mode
    st.sidebar.subheader("æ•ˆèƒ½ (Performance)")
    perf_mode = st.sidebar.radio(
        "è™•ç†æ¨¡å¼ (Processing Mode)",
        ("Balanced (Default)", "High Accuracy", "Turbo Speed"),
        index=0,
        help="High Accuracy: é€å¹€è™•ç†\nBalanced: æ¯ 2 å¹€è™•ç†ä¸€æ¬¡ (æ¨è–¦)\nTurbo: æ¯ 3 å¹€è™•ç†ä¸€æ¬¡ (æœ€å¿«ï¼Œé©åˆé•·å½±ç‰‡)"
    )
    
    frame_skip = 1 # Default Balanced
    if perf_mode == "High Accuracy":
        frame_skip = 0
    elif perf_mode == "Turbo Speed":
        frame_skip = 2

    # --- 2. å‰ªè¼¯ (Trim) ---
    st.header("2. è¨­å®šåˆ†æç¯„åœ")
    st.info("ğŸ’¡ æ‹–æ›³æ»‘æ¡¿ä¾†é¸æ“‡èµ·å§‹èˆ‡çµæŸé» (å³æ™‚é è¦½)")
    
    # Trim Sliders with Preview
    col_t1, col_t2 = st.columns(2)
    with col_t1:
        start_t = st.slider("é–‹å§‹æ™‚é–“ (s)", 0.0, duration, 0.0, step=0.1)
        cap.set(cv2.CAP_PROP_POS_MSEC, start_t * 1000)
        ret_s, frame_s = cap.read()
        if ret_s:
            if rotation_code is not None:
                frame_s = cv2.rotate(frame_s, rotation_code)
            st.image(frame_s, channels="BGR", caption=f"Start: {start_t}s", width=300)
            
    with col_t2:
        end_t = st.slider("çµæŸæ™‚é–“ (s)", 0.0, duration, duration, step=0.1)
        cap.set(cv2.CAP_PROP_POS_MSEC, end_t * 1000)
        ret_e, frame_e = cap.read()
        if ret_e:
            if rotation_code is not None:
                frame_e = cv2.rotate(frame_e, rotation_code)
            st.image(frame_e, channels="BGR", caption=f"End: {end_t}s", width=300)

    if start_t >= end_t:
        st.error("çµæŸæ™‚é–“å¿…é ˆå¤§æ–¼é–‹å§‹æ™‚é–“")
        st.stop()
        
    # --- Advanced Settings (Analysis Thresholds) ---
    with st.expander("âš™ï¸ é€²éšè¨­å®š (Analysis Settings)"):
        st.caption("è‹¥ç„¡æ³•åµæ¸¬åˆ°è¼ƒæ…¢çš„æ¬¡æ•¸ (Grinders)ï¼Œè«‹å˜—è©¦é™ä½é€Ÿåº¦é–€æª»")
        min_velo_threshold = st.slider("æœ€å°é€Ÿåº¦é–€æª» (Min Velocity, m/s)", 0.05, 1.0, 0.20, step=0.05)
        smooth_window = st.slider("å¹³æ»‘ä¿‚æ•¸ (Smoothing Window)", 3, 21, 9, step=2)

    # è®€å–åˆ†æèµ·å§‹å¹€ (ç”¨æ–¼ç•«æ¡†)
    cap.set(cv2.CAP_PROP_POS_MSEC, start_t * 1000)
    ret, first_frame = cap.read()
    
    if ret:
        if rotation_code is not None:
            first_frame = cv2.rotate(first_frame, rotation_code)

        h_orig, w_orig = first_frame.shape[:2]
        
        # --- 3. æ ¡å‡†èˆ‡è¿½è¹¤è¨­å®š (Canvas) ---
        st.header("3. æ ¡æº–èˆ‡ç›®æ¨™è¨­å®š")
        
        # --- Mobile Optimization (Moved to Global Settings) ---
        # is_mobile definition moved to top
        
        if is_mobile:
            max_canvas_width = 300 # Reduced to 300 to fit smaller screens (iPhone SE is 320px)
            max_canvas_height = 500
        else:
            max_canvas_width = 800
            max_canvas_height = 600

        # Instructions in expander
        with st.expander("ğŸ‘‰ ç¹ªåœ–æ“ä½œèªªæ˜ (æŒ‰æ­¤å±•é–‹)", expanded=not is_mobile):
             st.info("ğŸ‘‡ æ“ä½œèªªæ˜")
             st.markdown("è«‹åœ¨ä¸‹æ–¹åœ–ç‰‡ä¸Šä¾åºç•«æ¡† (ç´… -> ç¶ )ï¼š")
             st.markdown("1. **ç´…è‰²æ¡†**: æ ¡æº–æ§“ç‰‡")
             st.markdown("2. **ç¶ è‰²æ¡†**: è¿½è¹¤ç›®æ¨™")
             if is_mobile:
                 st.markdown("---")
                 st.warning("ğŸ“± **æ‰‹æ©Ÿæ“ä½œæç¤º**:")
                 st.markdown("- **å–®æŒ‡ (One Finger)**: ç•«æ¡† (è«‹ç”¨åŠ›æŒ‰å£“ä¸¦æ‹–æ›³)")
                 st.markdown("- **é›™æŒ‡ (Two Fingers)**: æ²å‹•é é¢")
                 st.markdown("- è‹¥ç„¡æ³•ç•«åœ–ï¼Œè«‹ç¢ºä¿ç¶²é æ²’æœ‰æ”¾å¤§ç¸®å°")

        from streamlit_drawable_canvas import st_canvas
        from PIL import Image

        # ç¸®æ”¾åœ–ç‰‡ä»¥é©æ‡‰ç•«å¸ƒ
        h_orig, w_orig = first_frame.shape[:2]
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
        scale_w = max_canvas_width / w_orig
        scale_h = max_canvas_height / h_orig
        canvas_scale = min(1.0, scale_w, scale_h)
        
        display_w = int(w_orig * canvas_scale)
        display_h = int(h_orig * canvas_scale)
        
        frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
        frame_pil = Image.fromarray(frame_rgb).resize((display_w, display_h))
        
        if "stroke_color" not in st.session_state:
            st.session_state.stroke_color = "#FF0000"

        # --- Inline Canvas (Pre-defined Boxes for Mobile Ease) ---
        st.markdown("##### æ­¥é©Ÿ 3.1: èª¿æ•´æ¡†çš„ä½ç½®")
        st.info("ğŸ‘† ç›´æ¥æ‹–æ›³æ¡†åˆ°æ­£ç¢ºä½ç½®ã€‚ **ç´…è‰²=æ§“ç‰‡** (æ ¡æº–ç”¨), **ç¶ è‰²=è¿½è¹¤ç›®æ¨™**")
        
        # Initial Drawing Objects (Fabric.js JSON format)
        if "initial_drawing" not in st.session_state:
            # Default positions: consistent logic regardless of image size, but use absolute pixels
            # Plate (Red) top-leftish, Target (Green) centerish
            st.session_state.initial_drawing = {
                "version": "4.4.0",
                "objects": [
                    {
                        "type": "rect",
                        "left": int(display_w * 0.1),
                        "top": int(display_h * 0.8),
                        "width": 100,
                        "height": 100,
                        "fill": "rgba(255, 0, 0, 0.2)",
                        "stroke": "#FF0000",
                        "strokeWidth": 3
                    },
                    {
                        "type": "rect",
                        "left": int(display_w * 0.4),
                        "top": int(display_h * 0.3),
                        "width": 100,
                        "height": 100,
                        "fill": "rgba(0, 255, 0, 0.2)",
                        "stroke": "#00FF00",
                        "strokeWidth": 3
                    }
                ]
            }

        # Canvas
        c_result = st_canvas(
            fill_color="rgba(255, 165, 0, 0.1)",
            stroke_width=3,
            background_image=frame_pil,
            update_streamlit=True,
            height=display_h,
            width=display_w,
            drawing_mode="transform", # Only allow moving/resizing
            initial_drawing=st.session_state.initial_drawing,
            key="main_canvas_transform",
            display_toolbar=False, # Hide toolbar
        )
        
        # Process Canvas Result & Color Logic
        plate_rect = None
        target_rect = None
        
        if c_result.json_data is not None:
            objects = c_result.json_data["objects"]
            
            # Identify by color
            for obj in objects:
                color = obj.get("stroke", "").upper()
                left = int(obj["left"] / canvas_scale)
                top = int(obj["top"] / canvas_scale)
                w = int(obj["width"] * obj.get("scaleX", 1) / canvas_scale)
                h = int(obj["height"] * obj.get("scaleY", 1) / canvas_scale)
                
                rect = (left, top, w, h)
                
                if color == "#FF0000":
                    plate_rect = rect
                elif color == "#00FF00":
                    target_rect = rect

            if plate_rect and target_rect:
                st.success(f"âœ… è¨­å®šå®Œæˆ! æ§“ç‰‡: {plate_rect}, ç›®æ¨™: {target_rect}")
            else:
                 # Should theoretically not happen unless they delete it (which is hard without toolbar)
                 st.warning("âš ï¸ æª¢æ¸¬ä¸åˆ°æ¡†ï¼Œè«‹é‡æ–°æ•´ç†ç¶²é ")

        # --- 4. åŸ·è¡Œåˆ†æ ---
        st.markdown("###")
        btn_disabled = (plate_rect is None or target_rect is None)
        
        if st.button("ğŸš€ é–‹å§‹æ™ºèƒ½åˆ†æ (Start Analysis)", type="primary", disabled=btn_disabled):
            if btn_disabled:
                st.error("è«‹å…ˆå®Œæˆæ ¡æº–ç‰©èˆ‡ç›®æ¨™çš„æ¡†é¸ï¼")
                st.stop()
            
            # --- åˆå§‹åŒ–æ•¸æ“š ---
            st.write("æ­£åœ¨è™•ç†å½±åƒ... (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ä½¿ç”¨æˆ‘å€‘å¾ Canvas æ‹¿åˆ°çš„åº§æ¨™ï¼Œè€Œä¸æ˜¯ Sliders
            (plate_x, plate_y, plate_w, plate_h) = plate_rect
            # Plate Size ç”¨å¯¬åº¦æˆ–é«˜åº¦çš„å¹³å‡ï¼Œæˆ–åŸæœ¬é‚è¼¯
            # åœ¨åŸ logic ä¸­ plate_s åªæœ‰ä¸€å€‹ç¶­åº¦ï¼Œé€™è£¡æˆ‘å€‘å–æœ€å¤§é‚Šä½œç‚ºç›´å¾‘ä¼°è¨ˆ
            plate_s = max(plate_w, plate_h) 
            
            (bar_x, bar_y, bar_w, bar_h) = target_rect

            # 1. è¨­ç½® Tracker
            # 2. å„ªåŒ–: è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ (Process Scale) ä»¥åŠ é€Ÿè™•ç†
            target_width = 640  # é™åˆ¶è™•ç†å¯¬åº¦ç‚º 640pxï¼Œå¤§å¹…æå‡ç¶²é ç«¯é€Ÿåº¦
            process_scale = target_width / float(w_orig)
            
            # ä¾æ¯”ä¾‹ç¸®å° ROI
            roi_track_small = (int(bar_x * process_scale),
                               int(bar_y * process_scale),
                               int(bar_w * process_scale),
                               int(bar_h * process_scale))
            
            # ä¾æ¯”ä¾‹ç¸®å°ç¬¬ä¸€å¹€ä¸¦åˆå§‹åŒ–
            first_frame_small = cv2.resize(first_frame, (0,0), fx=process_scale, fy=process_scale)
            tracker = cv2.TrackerCSRT_create()
            tracker.init(first_frame_small, roi_track_small)
            
            # è¨ˆç®—çœŸå¯¦ä¸–ç•Œæ¯”ä¾‹å°º (Meters per Pixel)
            # å‡è¨­æ¨™æº–ç‰‡ç›´å¾‘ 0.45 ç±³ (45cm)
            meters_per_pixel = 0.45 / float(plate_s) 
            
            positions = []
            times = []
            
            start_frame = int(start_t * fps)
            curr_frame_idx = start_frame
            end_frame_idx = int(end_t * fps)
            total_frames = end_frame_idx - start_frame
            
            # --- åˆ†æè¿´åœˆ ---
            # --- åˆ†æè¿´åœˆ (Optimized with Threading) ---
            # Start the threaded video reader
            video_reader = ThreadedVideoReader(video_path, start_frame, end_frame_idx, process_scale, rotation_code)
            video_reader.start()
            
            while video_reader.more():
                item = video_reader.read()
                if item is None:
                    break
                    
                (ret, frame_small, idx) = item
                if not ret:
                    break
                
                # Performance Optimization: Frame Skipping
                current_process_idx = idx - start_frame
                
                # Default assume success for skipped frames (we will interpolate later)
                # But for tracking, we only update tracker on specific frames
                
                if current_process_idx == 0 or current_process_idx % (frame_skip + 1) == 0:
                    success, box = tracker.update(frame_small)
                    
                    if success:
                        (x, y, bw, bh) = [int(v) for v in box]
                        cy_small = y + bh/2
                        cy_original = cy_small / process_scale
                        
                        positions.append(cy_original)
                        times.append(idx / fps)
                
                # æ›´æ–°é€²åº¦æ¢ (æ¯ 10 å¹€æ›´æ–°ä¸€æ¬¡ä»¥ç¯€çœè³‡æº)
                if total_frames > 0 and idx % 10 == 0:
                    prog = (idx - start_frame) / total_frames
                    progress_bar.progress(min(prog, 1.0))
            
            progress_bar.progress(1.0)
            video_reader.stop()
            
            # --- 5. æ•¸æ“šå¾Œè™•ç† (Data Post-Processing) ---
            if len(positions) > 5:
                # Interpolation for Performance Mode
                if frame_skip > 0 and len(positions) > 1:
                    full_times = np.linspace(times[0], times[-1], int((times[-1]-times[0])*fps))
                    full_positions = np.interp(full_times, times, positions)
                    
                    time_array = full_times
                    pos_array = full_positions
                else:
                    pos_array = np.array(positions)
                    time_array = np.array(times)
                
                # A. åƒç´ è½‰ä½ç§» (Yè»¸å‘ä¸‹ç‚ºæ­£ï¼Œéœ€åè½‰)
                # å‡è¨­èµ·å§‹ä½ç½®ç‚º 0ï¼Œå‘ä¸Šç§»å‹•ç‚ºæ­£
                height_pixels = -(pos_array - pos_array[0])
                height_m = height_pixels * meters_per_pixel
                height_smooth = smooth_data(height_m, 15) # å¹³æ»‘ä½ç§»
                
                # B. è¨ˆç®—é€Ÿåº¦ (Gradient)
                velocity = np.gradient(height_smooth, time_array)
                velocity_smooth = smooth_data(velocity, smooth_window) # ä½¿ç”¨è‡ªå®šç¾©å¹³æ»‘ä¿‚æ•¸
                
                # C. å°‹æ‰¾ Reps (Peak Detection) - ç§»æ¤è‡ª Desktop ç‰ˆ
                candidate_peaks = []
                # é–¾å€¼ï¼šé€Ÿåº¦å¿…é ˆå¤§æ–¼ min_velo_threshold ä¸”æ˜¯å±€éƒ¨æœ€å¤§å€¼
                for i in range(1, len(velocity_smooth)-1):
                    if velocity_smooth[i] > velocity_smooth[i-1] and velocity_smooth[i] > velocity_smooth[i+1]:
                        if velocity_smooth[i] > min_velo_threshold:
                            candidate_peaks.append({'v': velocity_smooth[i], 't': time_array[i], 'idx': i})
                
                # D. åˆä½µæ¥è¿‘çš„ Peaks (Merge Reps)
                reps = []
                merge_window = 1.5  # ç§’
                
                for peak in candidate_peaks:
                    if not reps:
                        reps.append(peak)
                    else:
                        last_rep = reps[-1]
                        if (peak['t'] - last_rep['t']) < merge_window:
                            # å¦‚æœæ™‚é–“å¤ªè¿‘ï¼Œä¿ç•™é€Ÿåº¦è¼ƒå¤§çš„é‚£å€‹
                            if peak['v'] > last_rep['v']:
                                reps[-1] = peak
                        else:
                            reps.append(peak)
                            
                peak_vs = [r['v'] for r in reps]
                num_reps = len(reps)
                
                # E. è¨ˆç®—é€²éšçµ±è¨ˆ (Biggest Drop, etc.)
                avg_v = np.mean(peak_vs) if peak_vs else 0
                min_v = np.min(peak_vs) if peak_vs else 0
                max_v = np.max(peak_vs) if peak_vs else 0
                
                biggest_drop_pct = 0
                drop_reps_indices = (-1, -1) # (index of rep A, index of rep B)
                
                # Logic synchronized with Desktop App: Find Biggest Absolute Drop first
                if num_reps > 1:
                    max_drop_val = 0
                    v_start_for_pct = 0
                    
                    for i in range(num_reps - 1):
                        drop = peak_vs[i] - peak_vs[i+1]
                        if drop > max_drop_val:
                            max_drop_val = drop
                            v_start_for_pct = peak_vs[i]
                            drop_reps_indices = (i, i+1) # 0-based index
                            
                    # Calculate Percentage for the biggest absolute drop
                    if max_drop_val > 0 and v_start_for_pct > 0:
                        biggest_drop_pct = (max_drop_val / v_start_for_pct) * 100
                
                # --- 6. çµæœå±•ç¤º ---
                st.success(f"åˆ†æå®Œæˆï¼åµæ¸¬åˆ° {num_reps} çµ„å‹•ä½œ (Reps)")
                
                # çµ±è¨ˆæ•¸æ“šå¡ç‰‡
                c1, c2, c3 = st.columns(3)
                c1.metric("å¹³å‡å³°å€¼é€Ÿåº¦", f"{avg_v:.2f} m/s", delta=f"Max: {max_v:.2f}")
                c2.metric("æœ€æ…¢ä¸€ä¸‹ (Slowest)", f"{min_v:.2f} m/s")
                
                drop_str = f"{biggest_drop_pct:.1f}%"
                drop_label = "æœ€å¤§é™å¹… (Drop)"
                if drop_reps_indices[0] != -1:
                    drop_label += f" (R{drop_reps_indices[0]+1} -> R{drop_reps_indices[1]+1})"
                c3.metric(drop_label, drop_str, delta_color="inverse" if biggest_drop_pct > 10 else "normal")

                # --- ç¹ªåœ– (Matplotlib) ---
                fig, ax = plt.subplots(figsize=(10, 5))
                # ç¹ªè£½é€Ÿåº¦æ›²ç·š
                ax.plot(time_array, velocity_smooth, color='#1f77b4', linewidth=2, label='Velocity', alpha=0.8)
                ax.axhline(0, color='black', alpha=0.3, linewidth=1)
                
                # æ¨™è¨˜ Reps
                for i, r in enumerate(reps):
                    rep_num = i + 1
                    # é è¨­é¡è‰²
                    color = 'red'
                    size = 50
                    
                    # å¦‚æœæ˜¯æœ€å¤§é™å¹…æ¶‰åŠçš„é‚£å…©ä¸‹ï¼Œæ”¹ç‚ºç´«è‰²
                    if drop_reps_indices[0] != -1:
                        if i == drop_reps_indices[0] or i == drop_reps_indices[1]:
                            color = 'purple'
                            size = 80
                    
                    ax.scatter(r['t'], r['v'], color=color, s=size, zorder=5)
                    ax.annotate(f"{r['v']:.2f}\n(R{rep_num})", 
                                (r['t'], r['v']), 
                                xytext=(0, 15), 
                                textcoords='offset points', 
                                ha='center', 
                                fontsize=9, 
                                fontweight='bold',
                                color='#333')
                
                ax.set_title(f"Velocity Profile ({num_reps} Reps)", fontsize=12)
                ax.set_ylabel("Speed (m/s)")
                ax.set_xlabel("Time (s)")
                ax.grid(True, alpha=0.3, linestyle='--')
                
                st.pyplot(fig)
                
                # --- ä¸‹è¼‰æ•¸æ“š ---
                df = pd.DataFrame({
                    "Time": time_array, 
                    "Velocity": velocity_smooth, 
                    "Height": height_smooth
                })
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ ä¸‹è¼‰è©³ç´° CSV æ•¸æ“š", csv, "barbell_analysis.csv", "text/csv")
                
            else:
                st.error("âŒ è¿½è¹¤å¤±æ•—æˆ–æ•¸æ“šå¤ªçŸ­ã€‚è«‹å˜—è©¦ï¼š\n1. èª¿æ•´ç¶ è‰²è¿½è¹¤æ¡†çš„ä½ç½®\n2. ç¢ºä¿å½±ç‰‡å…‰ç·šå……è¶³ä¸”èƒŒæ™¯å–®ç´”")

    else:
        st.error("ç„¡æ³•è®€å–å½±ç‰‡å¹€ï¼Œè«‹æª¢æŸ¥å½±ç‰‡æ ¼å¼ã€‚")