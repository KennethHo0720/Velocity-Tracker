import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tempfile
import pandas as pd
import threading
import queue
import queue
import time
import base64
import io

# --- é é¢é…ç½® ---
st.set_page_config(page_title="Barbell Tracker Pro V2", layout="wide") 

# è‡ªå®šç¾© CSS ä»¥å„ªåŒ–æ‰‹æ©Ÿé¡¯ç¤º
st.markdown("""
    <style>
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .stMetric { background-color: #f0f2f6; padding: 10px; border-radius: 8px; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‹ï¸ æ éˆ´é€Ÿåº¦åˆ†æ V2 (Web)")
st.caption("ç§»æ¤è‡ª Desktop Pro ç‰ˆ | æ”¯æ´ Reps åµæ¸¬èˆ‡é™å¹…åˆ†æ")
st.markdown("---")

# --- è¼”åŠ©å‡½æ•¸: å¹³æ»‘è™•ç† ---
def smooth_data(data, window_size):
    if len(data) < window_size: return data
    window = np.hanning(window_size)
    window = window / window.sum()
    return np.convolve(data, window, mode='same')

class ThreadedVideoReader:
    def __init__(self, path, start_frame, end_frame, scale_factor, rotation_code=None):
        self.path = path
        self.start_frame = start_frame
        self.end_frame = end_frame
        self.scale_factor = scale_factor
        self.rotation_code = rotation_code
        self.queue = queue.Queue(maxsize=1024) # Buffer size increased for performance
        self.stopped = False
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
    
    def start(self):
        self.thread.start()
        return self

    def update(self):
        cap = cv2.VideoCapture(self.path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
        current_idx = self.start_frame

        while current_idx < self.end_frame:
            if self.stopped:
                break
            
            if not self.queue.full():
                ret, frame = cap.read()
                if not ret:
                    self.stop()
                    break
                
                # Rotation
                if self.rotation_code is not None:
                    frame = cv2.rotate(frame, self.rotation_code)

                # Pre-process in thread
                frame_small = cv2.resize(frame, (0,0), fx=self.scale_factor, fy=self.scale_factor)
                
                self.queue.put((ret, frame_small, current_idx))
                current_idx += 1
            else:
                time.sleep(0.01) # Wait a bit if queue is full

        cap.release()
        self.stopped = True

    def read(self):
        # Return next frame in the queue. 
        # returns (ret, frame, idx) or None if empty/finished
        try:
            return self.queue.get(timeout=1)
        except queue.Empty:
            return None

    def more(self):
        return not self.stopped or not self.queue.empty()

    def stop(self):
        self.stopped = True
        # Drain queue to allow thread to exit if blocked
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except queue.Empty:
                break


# --- 1. ä¸Šå‚³èˆ‡åˆå§‹åŒ– ---
st.header("1. ä¸Šå‚³å½±ç‰‡")
uploaded_file = st.file_uploader("é¸æ“‡å½±ç‰‡æ–‡ä»¶ (MP4/MOV)", type=['mp4', 'mov', 'avi'])

if uploaded_file is not None:
    # ä¿å­˜è‡¨æ™‚æ–‡ä»¶
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    video_path = tfile.name
    
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if np.isnan(fps) or fps < 1: fps = 30
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    # --- Global Settings (Sidebar) ---
    st.sidebar.header("è¨­å®š (Settings)")
    
    # 1. Mobile Optimization
    is_mobile = st.sidebar.checkbox("ğŸ“± æ‰‹æ©Ÿæ¨¡å¼ (Mobile View)", value=True, help="é–‹å•Ÿä»¥ç²å¾—æœ€ä½³æ‰‹æ©Ÿé«”é©—")
    
    # 2. Rotation (Auto Portrait)
    # Get Video Dimensions
    v_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    v_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    st.sidebar.subheader("å½±ç‰‡æ—‹è½‰ (Rotation)")
    auto_portrait = st.sidebar.checkbox("ğŸ”„ è‡ªå‹•è½‰æ­£ (Auto Portrait)", value=True, help="è‹¥å½±ç‰‡ç‚ºæ©«å‘ (å¯¬ > é«˜)ï¼Œè‡ªå‹•æ—‹è½‰ 90 åº¦")
    
    rotation_code = None
    
    if auto_portrait:
        if v_width > v_height:
            rotation_code = cv2.ROTATE_90_CLOCKWISE
            st.sidebar.info(f"å·²è‡ªå‹•æ—‹è½‰ 90 åº¦\n(åŸå§‹: {v_width}x{v_height})")
    else:
        # Manual Rotation
        rotate_option = st.sidebar.selectbox(
            "æ‰‹å‹•èª¿æ•´ (Manual)",
            options=[0, 90, 180, 270],
            index=0,
            help="è‹¥è‡ªå‹•è½‰æ­£ä¸æ­£ç¢ºï¼Œè«‹é—œé–‰è‡ªå‹•æ¨¡å¼ä¸¦æ‰‹å‹•é¸æ“‡"
        )
        
        if rotate_option == 90:
            rotation_code = cv2.ROTATE_90_CLOCKWISE
        elif rotate_option == 180:
            rotation_code = cv2.ROTATE_180
            rotation_code = cv2.ROTATE_90_COUNTERCLOCKWISE
            
    # 3. Performance / Speed Mode
    st.sidebar.subheader("æ•ˆèƒ½ (Performance)")
    perf_mode = st.sidebar.radio(
        "è™•ç†æ¨¡å¼ (Processing Mode)",
        ("Balanced (Default)", "High Accuracy", "Turbo Speed"),
        index=0,
        help="High Accuracy: é€å¹€è™•ç†\nBalanced: æ¯ 2 å¹€è™•ç†ä¸€æ¬¡ (æ¨è–¦)\nTurbo: æ¯ 3 å¹€è™•ç†ä¸€æ¬¡ (æœ€å¿«ï¼Œé©åˆé•·å½±ç‰‡)"
    )
    
    frame_skip = 1 # Default Balanced
    if perf_mode == "High Accuracy":
        frame_skip = 0
    elif perf_mode == "Turbo Speed":
        frame_skip = 2

    # --- 2. å‰ªè¼¯ (Trim) ---
    st.header("2. è¨­å®šåˆ†æç¯„åœ")
    st.info("ğŸ’¡ æ‹–æ›³æ»‘æ¡¿ä¾†é¸æ“‡èµ·å§‹èˆ‡çµæŸé» (å³æ™‚é è¦½)")
    
    # Trim Sliders with Preview
    col_t1, col_t2 = st.columns(2)
    with col_t1:
        start_t = st.slider("é–‹å§‹æ™‚é–“ (s)", 0.0, duration, 0.0, step=0.1)
        cap.set(cv2.CAP_PROP_POS_MSEC, start_t * 1000)
        ret_s, frame_s = cap.read()
        if ret_s:
            if rotation_code is not None:
                frame_s = cv2.rotate(frame_s, rotation_code)
            st.image(frame_s, channels="BGR", caption=f"Start: {start_t}s", width=300)
            
    with col_t2:
        end_t = st.slider("çµæŸæ™‚é–“ (s)", 0.0, duration, duration, step=0.1)
        cap.set(cv2.CAP_PROP_POS_MSEC, end_t * 1000)
        ret_e, frame_e = cap.read()
        if ret_e:
            if rotation_code is not None:
                frame_e = cv2.rotate(frame_e, rotation_code)
            st.image(frame_e, channels="BGR", caption=f"End: {end_t}s", width=300)

    if start_t >= end_t:
        st.error("çµæŸæ™‚é–“å¿…é ˆå¤§æ–¼é–‹å§‹æ™‚é–“")
        st.stop()
        
    # --- Advanced Settings (Analysis Thresholds) ---
    with st.expander("âš™ï¸ é€²éšè¨­å®š (Analysis Settings)"):
        st.caption("è‹¥ç„¡æ³•åµæ¸¬åˆ°è¼ƒæ…¢çš„æ¬¡æ•¸ (Grinders)ï¼Œè«‹å˜—è©¦é™ä½é€Ÿåº¦é–€æª»")
        min_velo_threshold = st.slider("æœ€å°é€Ÿåº¦é–€æª» (Min Velocity, m/s)", 0.05, 1.0, 0.20, step=0.05)
        smooth_window = st.slider("å¹³æ»‘ä¿‚æ•¸ (Smoothing Window)", 3, 21, 9, step=2)

    # è®€å–åˆ†æèµ·å§‹å¹€ (ç”¨æ–¼ç•«æ¡†)
    cap.set(cv2.CAP_PROP_POS_MSEC, start_t * 1000)
    ret, first_frame = cap.read()
    
    if ret:
        if rotation_code is not None:
            first_frame = cv2.rotate(first_frame, rotation_code)

        h_orig, w_orig = first_frame.shape[:2]
        
        # --- 3. æ ¡å‡†èˆ‡è¿½è¹¤è¨­å®š (Canvas) ---
        st.header("3. æ ¡æº–èˆ‡ç›®æ¨™è¨­å®š")
        
        # --- Mobile Optimization (Moved to Global Settings) ---
        # is_mobile definition moved to top
        
        if is_mobile:
            max_canvas_width = 350 # Typical mobile width
            max_canvas_height = 500
        else:
            max_canvas_width = 800
            max_canvas_height = 600

        # Instructions in expander to save space
        with st.expander("TODO: ç¹ªåœ–æ“ä½œèªªæ˜ (é»æ“Šå±•é–‹)", expanded=not is_mobile):
             st.info("ğŸ‘‡ æ“ä½œèªªæ˜")
             st.markdown("è«‹åœ¨ä¸‹æ–¹åœ–ç‰‡ä¸Šä¾åºç•«æ¡†ï¼š")
             st.markdown("1. **ç´…è‰²æ¡†**: æ ¡æº–æ§“ç‰‡")
             st.markdown("2. **ç¶ è‰²æ¡†**: è¿½è¹¤ç›®æ¨™")
             st.caption("æç¤º: æ‰‹æ©Ÿä¸Šè«‹ä½¿ç”¨é›™æŒ‡ç¸®æ”¾æˆ–æ‹–æ›³ä¾†èª¿æ•´ä½ç½®")

        from streamlit_drawable_canvas import st_canvas
        from PIL import Image

        # ç¸®æ”¾åœ–ç‰‡ä»¥é©æ‡‰ç•«å¸ƒ
        h_orig, w_orig = first_frame.shape[:2]
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
        scale_w = max_canvas_width / w_orig
        scale_h = max_canvas_height / h_orig
        canvas_scale = min(1.0, scale_w, scale_h)
        
        display_w = int(w_orig * canvas_scale)
        display_h = int(h_orig * canvas_scale)
        
        frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
        frame_pil = Image.fromarray(frame_rgb).resize((display_w, display_h))
        
        # Layout 
        # On mobile, we stack everything. On desktop, we can use columns
        if is_mobile:
             col_controls = st.container()
             col_canvas = st.container()
        else:
             col_controls, col_canvas = st.columns([1, 2])

        with col_controls:
            # ç•«å¸ƒè¨­å®š
            drawing_mode = st.selectbox(
                "é¸æ“‡ç¹ªè£½å·¥å…·:",
                ("rect", "transform"),
                format_func=lambda x: "ğŸ“¦ ç•«æ¡† (Rect)" if x == "rect" else "âœ‹ èª¿æ•´ (Transform)"
            )
            
            # --- Dynamic Color Logic ---
            if "stroke_color" not in st.session_state:
                st.session_state.stroke_color = "#FF0000" # Initial Red
                
            stroke_color = st.session_state.stroke_color
            
            # Show current color to user (read-only feedback)
            st.markdown(f"**ç•¶å‰ç­†åˆ·é¡è‰²**: <span style='color:{stroke_color}'>{'ğŸŸ¥ ç´…è‰² (æ ¡æº–ç‰©)' if stroke_color=='#FF0000' else 'ğŸŸ© ç¶ è‰² (è¿½è¹¤ç›®æ¨™)'}</span>", unsafe_allow_html=True)
            
            # Placeholder for status messages
            status_container = st.container()

        with col_canvas:
            # Create a canvas component
            # Center the canvas in mobile view for better aesthetic
            if is_mobile:
                 st.write("â–¼ è«‹åœ¨ä¸‹æ–¹ç¹ªåœ–")
            
            # Manual Base64 Conversion to bypass library bug with Streamlit 1.xx
            # This fixes "AttributeError: ... image_to_url" and Black Screen issues
            buffered = io.BytesIO()
            frame_pil.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            img_data_url = "data:image/png;base64," + img_str

            canvas_result = st_canvas(
                fill_color="rgba(255, 165, 0, 0.1)",
                stroke_width=3,
                stroke_color=stroke_color,
                background_image=img_data_url, # Pass Data URL instead of PIL object
                update_streamlit=True,
                height=display_h,
                width=display_w,
                drawing_mode=drawing_mode,
                key=f"canvas_{start_t}_mob_{is_mobile}_v2", 
            )

        plate_rect = None
        target_rect = None
        
        # Populate Status in Left Column
        with status_container:
            if canvas_result.json_data is not None:
                objects = canvas_result.json_data["objects"]
                obj_count = len(objects)
                
                # --- Update Color State if needed ---
                target_color = "#00FF00" if obj_count >= 1 else "#FF0000"
                if st.session_state.stroke_color != target_color:
                    st.session_state.stroke_color = target_color
                    st.rerun()

                if obj_count > 0:
                    obj1 = objects[0]
                    plate_rect = (
                        int(obj1["left"] / canvas_scale), 
                        int(obj1["top"] / canvas_scale), 
                        int(obj1["width"] / canvas_scale), 
                        int(obj1["height"] / canvas_scale)
                    )
                    st.success(f"âœ… æ ¡æº–ç‰©å·²è¨­å®š")

                    if obj_count > 1:
                        obj2 = objects[1]
                        target_rect = (
                            int(obj2["left"] / canvas_scale), 
                            int(obj2["top"] / canvas_scale), 
                            int(obj2["width"] / canvas_scale), 
                            int(obj2["height"] / canvas_scale)
                        )
                        st.success(f"âœ… è¿½è¹¤ç›®æ¨™å·²è¨­å®š")
                    else:
                        st.warning("âš ï¸ è«‹å†ç•«ä¸€å€‹æ¡†é¸å–è¿½è¹¤ç›®æ¨™")
                else:
                    st.info("ç­‰å¾…ç¹ªè£½ç¬¬ä¸€å€‹æ¡†...")

        # --- 4. åŸ·è¡Œåˆ†æ ---
        st.markdown("###")
        btn_disabled = (plate_rect is None or target_rect is None)
        
        if st.button("ğŸš€ é–‹å§‹æ™ºèƒ½åˆ†æ (Start Analysis)", type="primary", disabled=btn_disabled):
            if btn_disabled:
                st.error("è«‹å…ˆå®Œæˆæ ¡æº–ç‰©èˆ‡ç›®æ¨™çš„æ¡†é¸ï¼")
                st.stop()
            
            # --- åˆå§‹åŒ–æ•¸æ“š ---
            st.write("æ­£åœ¨è™•ç†å½±åƒ... (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ä½¿ç”¨æˆ‘å€‘å¾ Canvas æ‹¿åˆ°çš„åº§æ¨™ï¼Œè€Œä¸æ˜¯ Sliders
            (plate_x, plate_y, plate_w, plate_h) = plate_rect
            # Plate Size ç”¨å¯¬åº¦æˆ–é«˜åº¦çš„å¹³å‡ï¼Œæˆ–åŸæœ¬é‚è¼¯
            # åœ¨åŸ logic ä¸­ plate_s åªæœ‰ä¸€å€‹ç¶­åº¦ï¼Œé€™è£¡æˆ‘å€‘å–æœ€å¤§é‚Šä½œç‚ºç›´å¾‘ä¼°è¨ˆ
            plate_s = max(plate_w, plate_h) 
            
            (bar_x, bar_y, bar_w, bar_h) = target_rect

            # 1. è¨­ç½® Tracker
            # 2. å„ªåŒ–: è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ (Process Scale) ä»¥åŠ é€Ÿè™•ç†
            target_width = 640  # é™åˆ¶è™•ç†å¯¬åº¦ç‚º 640pxï¼Œå¤§å¹…æå‡ç¶²é ç«¯é€Ÿåº¦
            process_scale = target_width / float(w_orig)
            
            # ä¾æ¯”ä¾‹ç¸®å° ROI
            roi_track_small = (int(bar_x * process_scale),
                               int(bar_y * process_scale),
                               int(bar_w * process_scale),
                               int(bar_h * process_scale))
            
            # ä¾æ¯”ä¾‹ç¸®å°ç¬¬ä¸€å¹€ä¸¦åˆå§‹åŒ–
            first_frame_small = cv2.resize(first_frame, (0,0), fx=process_scale, fy=process_scale)
            tracker = cv2.TrackerCSRT_create()
            tracker.init(first_frame_small, roi_track_small)
            
            # è¨ˆç®—çœŸå¯¦ä¸–ç•Œæ¯”ä¾‹å°º (Meters per Pixel)
            # å‡è¨­æ¨™æº–ç‰‡ç›´å¾‘ 0.45 ç±³ (45cm)
            meters_per_pixel = 0.45 / float(plate_s) 
            
            positions = []
            times = []
            
            start_frame = int(start_t * fps)
            curr_frame_idx = start_frame
            end_frame_idx = int(end_t * fps)
            total_frames = end_frame_idx - start_frame
            
            # --- åˆ†æè¿´åœˆ ---
            # --- åˆ†æè¿´åœˆ (Optimized with Threading) ---
            # Start the threaded video reader
            video_reader = ThreadedVideoReader(video_path, start_frame, end_frame_idx, process_scale, rotation_code)
            video_reader.start()
            
            while video_reader.more():
                item = video_reader.read()
                if item is None:
                    break
                    
                (ret, frame_small, idx) = item
                if not ret:
                    break
                
                # Performance Optimization: Frame Skipping
                current_process_idx = idx - start_frame
                
                # Default assume success for skipped frames (we will interpolate later)
                # But for tracking, we only update tracker on specific frames
                
                if current_process_idx == 0 or current_process_idx % (frame_skip + 1) == 0:
                    success, box = tracker.update(frame_small)
                    
                    if success:
                        (x, y, bw, bh) = [int(v) for v in box]
                        cy_small = y + bh/2
                        cy_original = cy_small / process_scale
                        
                        positions.append(cy_original)
                        times.append(idx / fps)
                
                # æ›´æ–°é€²åº¦æ¢ (æ¯ 10 å¹€æ›´æ–°ä¸€æ¬¡ä»¥ç¯€çœè³‡æº)
                if total_frames > 0 and idx % 10 == 0:
                    prog = (idx - start_frame) / total_frames
                    progress_bar.progress(min(prog, 1.0))
            
            progress_bar.progress(1.0)
            video_reader.stop()
            
            # --- 5. æ•¸æ“šå¾Œè™•ç† (Data Post-Processing) ---
            if len(positions) > 5:
                # Interpolation for Performance Mode
                if frame_skip > 0 and len(positions) > 1:
                    full_times = np.linspace(times[0], times[-1], int((times[-1]-times[0])*fps))
                    full_positions = np.interp(full_times, times, positions)
                    
                    time_array = full_times
                    pos_array = full_positions
                else:
                    pos_array = np.array(positions)
                    time_array = np.array(times)
                
                # A. åƒç´ è½‰ä½ç§» (Yè»¸å‘ä¸‹ç‚ºæ­£ï¼Œéœ€åè½‰)
                # å‡è¨­èµ·å§‹ä½ç½®ç‚º 0ï¼Œå‘ä¸Šç§»å‹•ç‚ºæ­£
                height_pixels = -(pos_array - pos_array[0])
                height_m = height_pixels * meters_per_pixel
                height_smooth = smooth_data(height_m, 15) # å¹³æ»‘ä½ç§»
                
                # B. è¨ˆç®—é€Ÿåº¦ (Gradient)
                velocity = np.gradient(height_smooth, time_array)
                velocity_smooth = smooth_data(velocity, smooth_window) # ä½¿ç”¨è‡ªå®šç¾©å¹³æ»‘ä¿‚æ•¸
                
                # C. å°‹æ‰¾ Reps (Peak Detection) - ç§»æ¤è‡ª Desktop ç‰ˆ
                candidate_peaks = []
                # é–¾å€¼ï¼šé€Ÿåº¦å¿…é ˆå¤§æ–¼ min_velo_threshold ä¸”æ˜¯å±€éƒ¨æœ€å¤§å€¼
                for i in range(1, len(velocity_smooth)-1):
                    if velocity_smooth[i] > velocity_smooth[i-1] and velocity_smooth[i] > velocity_smooth[i+1]:
                        if velocity_smooth[i] > min_velo_threshold:
                            candidate_peaks.append({'v': velocity_smooth[i], 't': time_array[i], 'idx': i})
                
                # D. åˆä½µæ¥è¿‘çš„ Peaks (Merge Reps)
                reps = []
                merge_window = 1.5  # ç§’
                
                for peak in candidate_peaks:
                    if not reps:
                        reps.append(peak)
                    else:
                        last_rep = reps[-1]
                        if (peak['t'] - last_rep['t']) < merge_window:
                            # å¦‚æœæ™‚é–“å¤ªè¿‘ï¼Œä¿ç•™é€Ÿåº¦è¼ƒå¤§çš„é‚£å€‹
                            if peak['v'] > last_rep['v']:
                                reps[-1] = peak
                        else:
                            reps.append(peak)
                            
                peak_vs = [r['v'] for r in reps]
                num_reps = len(reps)
                
                # E. è¨ˆç®—é€²éšçµ±è¨ˆ (Biggest Drop, etc.)
                avg_v = np.mean(peak_vs) if peak_vs else 0
                min_v = np.min(peak_vs) if peak_vs else 0
                max_v = np.max(peak_vs) if peak_vs else 0
                
                biggest_drop_pct = 0
                drop_reps_indices = (-1, -1) # (index of rep A, index of rep B)
                
                # Logic synchronized with Desktop App: Find Biggest Absolute Drop first
                if num_reps > 1:
                    max_drop_val = 0
                    v_start_for_pct = 0
                    
                    for i in range(num_reps - 1):
                        drop = peak_vs[i] - peak_vs[i+1]
                        if drop > max_drop_val:
                            max_drop_val = drop
                            v_start_for_pct = peak_vs[i]
                            drop_reps_indices = (i, i+1) # 0-based index
                            
                    # Calculate Percentage for the biggest absolute drop
                    if max_drop_val > 0 and v_start_for_pct > 0:
                        biggest_drop_pct = (max_drop_val / v_start_for_pct) * 100
                
                # --- 6. çµæœå±•ç¤º ---
                st.success(f"åˆ†æå®Œæˆï¼åµæ¸¬åˆ° {num_reps} çµ„å‹•ä½œ (Reps)")
                
                # çµ±è¨ˆæ•¸æ“šå¡ç‰‡
                c1, c2, c3 = st.columns(3)
                c1.metric("å¹³å‡å³°å€¼é€Ÿåº¦", f"{avg_v:.2f} m/s", delta=f"Max: {max_v:.2f}")
                c2.metric("æœ€æ…¢ä¸€ä¸‹ (Slowest)", f"{min_v:.2f} m/s")
                
                drop_str = f"{biggest_drop_pct:.1f}%"
                drop_label = "æœ€å¤§é™å¹… (Drop)"
                if drop_reps_indices[0] != -1:
                    drop_label += f" (R{drop_reps_indices[0]+1} -> R{drop_reps_indices[1]+1})"
                c3.metric(drop_label, drop_str, delta_color="inverse" if biggest_drop_pct > 10 else "normal")

                # --- ç¹ªåœ– (Matplotlib) ---
                fig, ax = plt.subplots(figsize=(10, 5))
                # ç¹ªè£½é€Ÿåº¦æ›²ç·š
                ax.plot(time_array, velocity_smooth, color='#1f77b4', linewidth=2, label='Velocity', alpha=0.8)
                ax.axhline(0, color='black', alpha=0.3, linewidth=1)
                
                # æ¨™è¨˜ Reps
                for i, r in enumerate(reps):
                    rep_num = i + 1
                    # é è¨­é¡è‰²
                    color = 'red'
                    size = 50
                    
                    # å¦‚æœæ˜¯æœ€å¤§é™å¹…æ¶‰åŠçš„é‚£å…©ä¸‹ï¼Œæ”¹ç‚ºç´«è‰²
                    if drop_reps_indices[0] != -1:
                        if i == drop_reps_indices[0] or i == drop_reps_indices[1]:
                            color = 'purple'
                            size = 80
                    
                    ax.scatter(r['t'], r['v'], color=color, s=size, zorder=5)
                    ax.annotate(f"{r['v']:.2f}\n(R{rep_num})", 
                                (r['t'], r['v']), 
                                xytext=(0, 15), 
                                textcoords='offset points', 
                                ha='center', 
                                fontsize=9, 
                                fontweight='bold',
                                color='#333')
                
                ax.set_title(f"Velocity Profile ({num_reps} Reps)", fontsize=12)
                ax.set_ylabel("Speed (m/s)")
                ax.set_xlabel("Time (s)")
                ax.grid(True, alpha=0.3, linestyle='--')
                
                st.pyplot(fig)
                
                # --- ä¸‹è¼‰æ•¸æ“š ---
                df = pd.DataFrame({
                    "Time": time_array, 
                    "Velocity": velocity_smooth, 
                    "Height": height_smooth
                })
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ ä¸‹è¼‰è©³ç´° CSV æ•¸æ“š", csv, "barbell_analysis.csv", "text/csv")
                
            else:
                st.error("âŒ è¿½è¹¤å¤±æ•—æˆ–æ•¸æ“šå¤ªçŸ­ã€‚è«‹å˜—è©¦ï¼š\n1. èª¿æ•´ç¶ è‰²è¿½è¹¤æ¡†çš„ä½ç½®\n2. ç¢ºä¿å½±ç‰‡å…‰ç·šå……è¶³ä¸”èƒŒæ™¯å–®ç´”")

    else:
        st.error("ç„¡æ³•è®€å–å½±ç‰‡å¹€ï¼Œè«‹æª¢æŸ¥å½±ç‰‡æ ¼å¼ã€‚")