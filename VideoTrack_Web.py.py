import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tempfile
import pandas as pd
import threading
import queue
import time

# --- é é¢é…ç½® ---
st.set_page_config(page_title="Barbell Tracker Pro V2", layout="wide") 

# è‡ªå®šç¾© CSS ä»¥å„ªåŒ–æ‰‹æ©Ÿé¡¯ç¤º
st.markdown("""
    <style>
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .stMetric { background-color: #f0f2f6; padding: 10px; border-radius: 8px; }
    /* Mobile Touch Fix: Prevent scrolling when touching canvas */
    iframe[title="streamlit_drawable_canvas.st_canvas"] {
        touch-action: none; 
    }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‹ï¸ æ éˆ´é€Ÿåº¦åˆ†æ V2 (Web)")
st.caption("ç§»æ¤è‡ª Desktop Pro ç‰ˆ | æ”¯æ´ Reps åµæ¸¬èˆ‡é™å¹…åˆ†æ")
st.markdown("---")

# ---------------------------------------------------------
#  KALMAN FILTER (NEW ADDITION - Ported from Desktop)
# ---------------------------------------------------------
class SimpleKalmanFilter:
    def __init__(self, initial_value, initial_velocity=0.0, process_noise=0.005, measurement_noise=5.0):
        # ç‹€æ…‹å‘é‡ [ä½ç½®, é€Ÿåº¦]
        self.x = np.array([[initial_value], [initial_velocity]])
        
        # ç‹€æ…‹å…±è®Šç•°æ•¸çŸ©é™£ P (åˆå§‹ä¸ç¢ºå®šæ€§)
        self.P = np.eye(2) * 1.0
        
        # ç‹€æ…‹è½‰ç§»çŸ©é™£ F (å‡è¨­æ†å®šé€Ÿåº¦æ¨¡å‹: pos = pos + vel*dt)
        # dt æœƒåœ¨ update æ™‚å‹•æ…‹æ‡‰ç”¨ï¼Œé€™è£¡å…ˆè¨­åŸºç¤çµæ§‹
        self.F = np.eye(2)
        
        # æ¸¬é‡çŸ©é™£ H (æˆ‘å€‘åªæ¸¬é‡ä½ç½®)
        self.H = np.array([[1.0, 0.0]])
        
        # æ¸¬é‡é›œè¨Š R (æ„Ÿæ¸¬å™¨/è¿½è¹¤èª¤å·®)
        self.R = np.array([[measurement_noise]])
        
        # éç¨‹é›œè¨Š Q (ç³»çµ±å…§éƒ¨è®ŠåŒ–ï¼Œå¦‚é‹å‹•å“¡çªç„¶ç™¼åŠ›)
        self.Q_base = process_noise

    def process(self, measurement, dt):
        if dt <= 0: return self.x[0, 0], self.x[1, 0]

        # 1. æ›´æ–°ç‹€æ…‹è½‰ç§»çŸ©é™£ F å’Œéç¨‹é›œè¨Š Q
        self.F[0, 1] = dt
        
        # Q çŸ©é™£æ§‹å»º (Discrete White Noise Acceleration Model)
        # å…è¨±é€Ÿåº¦éš¨æ™‚é–“è®ŠåŒ– (åŠ é€Ÿåº¦)
        q_pos = (dt**4)/4
        q_pos_vel = (dt**3)/2
        q_vel = (dt**2)
        
        Q = np.array([
            [q_pos, q_pos_vel],
            [q_pos_vel, q_vel]
        ]) * self.Q_base

        # 2. é æ¸¬ (Predict)
        self.x = np.dot(self.F, self.x)
        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + Q

        # 3. æ›´æ–° (Update)
        z = np.array([[measurement]])
        y = z - np.dot(self.H, self.x) # Residual
        S = np.dot(np.dot(self.H, self.P), self.H.T) + self.R
        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S)) # Kalman Gain
        
        self.x = self.x + np.dot(K, y)
        I = np.eye(2)
        self.P = np.dot((I - np.dot(K, self.H)), self.P)

        # è¿”å›å¹³æ»‘å¾Œçš„ä½ç½®å’Œé€Ÿåº¦
        return self.x[0, 0], self.x[1, 0]

def apply_kalman_filter(data, R=0.1, Q=100.0):
    # Backward compatibility wrapper if needed, or just placeholder
    # In the new logic we won't use this, but keeping it just in case of reference error until fully replaced.
    # Actually, we will remove usages.
    pass

class ThreadedVideoReader:
    def __init__(self, path, start_frame, end_frame, scale_factor, rotation_code=None):
        self.path = path
        self.start_frame = start_frame
        self.end_frame = end_frame
        self.scale_factor = scale_factor
        self.rotation_code = rotation_code
        self.queue = queue.Queue(maxsize=1024) # Buffer size increased for performance
        self.stopped = False
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
    
    def start(self):
        self.thread.start()
        return self

    def update(self):
        cap = cv2.VideoCapture(self.path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
        current_idx = self.start_frame

        while current_idx < self.end_frame:
            if self.stopped:
                break
            
            if not self.queue.full():
                ret, frame = cap.read()
                if not ret:
                    self.stop()
                    break
                
                # Rotation
                if self.rotation_code is not None:
                    frame = cv2.rotate(frame, self.rotation_code)

                # Pre-process in thread
                frame_small = cv2.resize(frame, (0,0), fx=self.scale_factor, fy=self.scale_factor)
                
                self.queue.put((ret, frame_small, current_idx))
                current_idx += 1
            else:
                time.sleep(0.01) # Wait a bit if queue is full

        cap.release()
        self.stopped = True

    def read(self):
        # Return next frame in the queue. 
        # returns (ret, frame, idx) or None if empty/finished
        try:
            return self.queue.get(timeout=1)
        except queue.Empty:
            return None

    def more(self):
        return not self.stopped or not self.queue.empty()

    def stop(self):
        self.stopped = True
        # Drain queue to allow thread to exit if blocked
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except queue.Empty:
                break


# --- 1. ä¸Šå‚³èˆ‡åˆå§‹åŒ– ---
st.header("1. ä¸Šå‚³å½±ç‰‡")
uploaded_file = st.file_uploader("é¸æ“‡å½±ç‰‡æ–‡ä»¶ (MP4/MOV)", type=['mp4', 'mov', 'avi'])

if uploaded_file is not None:
    # Check if a new file is uploaded
    if "last_uploaded" not in st.session_state or st.session_state.last_uploaded != uploaded_file.name:
        st.session_state.last_uploaded = uploaded_file.name
        # Clear specific session state keys to force reset
        keys_to_reset = ["initial_drawing", "stroke_color"]
        for k in keys_to_reset:
            if k in st.session_state:
                del st.session_state[k]

    # ä¿å­˜è‡¨æ™‚æ–‡ä»¶
    # Use delete=False to keep file for OpenCV processing
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') 
    tfile.write(uploaded_file.read())
    tfile.close() # Close the file so OpenCV can open it safely on Windows
    video_path = tfile.name
    
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if np.isnan(fps) or fps < 1: fps = 30
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    # --- Global Settings (Sidebar) ---
    st.sidebar.header("è¨­å®š (Settings)")
    
    # 1. Mobile Optimization
    is_mobile = st.sidebar.checkbox("ğŸ“± æ‰‹æ©Ÿæ¨¡å¼ (Mobile View)", value=True, help="é–‹å•Ÿä»¥ç²å¾—æœ€ä½³æ‰‹æ©Ÿé«”é©—")
    
    # 2. Rotation (Auto Portrait)
    # Get Video Dimensions
    v_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    v_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    st.sidebar.subheader("å½±ç‰‡æ—‹è½‰ (Rotation)")
    auto_portrait = st.sidebar.checkbox("ğŸ”„ è‡ªå‹•è½‰æ­£ (Auto Portrait)", value=True, help="è‹¥å½±ç‰‡ç‚ºæ©«å‘ (å¯¬ > é«˜)ï¼Œè‡ªå‹•æ—‹è½‰ 90 åº¦")
    
    rotation_code = None
    
    if auto_portrait:
        if v_width > v_height:
            rotation_code = cv2.ROTATE_90_CLOCKWISE
            st.sidebar.info(f"å·²è‡ªå‹•æ—‹è½‰ 90 åº¦\n(åŸå§‹: {v_width}x{v_height})")
    else:
        # Manual Rotation
        rotate_option = st.sidebar.selectbox(
            "æ‰‹å‹•èª¿æ•´ (Manual)",
            options=[0, 90, 180, 270],
            index=0,
            help="è‹¥è‡ªå‹•è½‰æ­£ä¸æ­£ç¢ºï¼Œè«‹é—œé–‰è‡ªå‹•æ¨¡å¼ä¸¦æ‰‹å‹•é¸æ“‡"
        )
        
        if rotate_option == 90:
            rotation_code = cv2.ROTATE_90_CLOCKWISE
        elif rotate_option == 180:
            rotation_code = cv2.ROTATE_180
        elif rotate_option == 270:
            rotation_code = cv2.ROTATE_90_COUNTERCLOCKWISE
            
    # 3. Performance / Speed Mode
    st.sidebar.subheader("æ•ˆèƒ½ (Performance)")
    perf_mode = st.sidebar.radio(
        "è™•ç†æ¨¡å¼ (Processing Mode)",
        ("Balanced (Default)", "High Accuracy", "Turbo Speed"),
        index=0,
        help="High Accuracy: é€å¹€è™•ç†\nBalanced: æ¯ 2 å¹€è™•ç†ä¸€æ¬¡ (æ¨è–¦)\nTurbo: æ¯ 3 å¹€è™•ç†ä¸€æ¬¡ (æœ€å¿«ï¼Œé©åˆé•·å½±ç‰‡)"
    )
    
    frame_skip = 1 # Default Balanced
    if perf_mode == "High Accuracy":
        frame_skip = 0
    elif perf_mode == "Turbo Speed":
        frame_skip = 2

    # --- 2. å‰ªè¼¯ (Trim) ---
    st.header("2. è¨­å®šåˆ†æç¯„åœ")
    st.info("ğŸ’¡ æ‹–æ›³æ»‘æ¡¿ä¾†é¸æ“‡èµ·å§‹èˆ‡çµæŸé» (å³æ™‚é è¦½)")
    
    # Trim Sliders with Preview
    col_t1, col_t2 = st.columns(2)
    with col_t1:
        start_t = st.slider("é–‹å§‹æ™‚é–“ (s)", 0.0, duration, 0.0, step=0.1)
        cap.set(cv2.CAP_PROP_POS_MSEC, start_t * 1000)
        ret_s, frame_s = cap.read()
        if ret_s:
            if rotation_code is not None:
                frame_s = cv2.rotate(frame_s, rotation_code)
            st.image(frame_s, channels="BGR", caption=f"Start: {start_t}s", width=300)
            
    with col_t2:
        end_t = st.slider("çµæŸæ™‚é–“ (s)", 0.0, duration, duration, step=0.1)
        cap.set(cv2.CAP_PROP_POS_MSEC, end_t * 1000)
        ret_e, frame_e = cap.read()
        if ret_e:
            if rotation_code is not None:
                frame_e = cv2.rotate(frame_e, rotation_code)
            st.image(frame_e, channels="BGR", caption=f"End: {end_t}s", width=300)

    if start_t >= end_t:
        st.error("çµæŸæ™‚é–“å¿…é ˆå¤§æ–¼é–‹å§‹æ™‚é–“")
        st.stop()
        
    # --- Advanced Settings (Analysis Thresholds) ---
    with st.expander("âš™ï¸ é€²éšè¨­å®š (Analysis Settings)"):
        st.caption("è‹¥ç„¡æ³•åµæ¸¬åˆ°è¼ƒæ…¢çš„æ¬¡æ•¸ (Grinders)ï¼Œè«‹å˜—è©¦é™ä½é€Ÿåº¦é–€æª»")
        min_velo_threshold = st.slider("æœ€å°é€Ÿåº¦é–€æª» (Min Velocity, m/s)", 0.05, 1.0, 0.20, step=0.05)
        kalman_r = st.slider("æ¿¾æ³¢å¼·åº¦ (Kalman R)", 0.01, 1.0, 0.1, step=0.01, help="æ•¸å€¼è¶Šå¤§ï¼Œå¹³æ»‘æ•ˆæœè¶Šå¼·ï¼Œä½†å»¶é²è¶Šé«˜")
        min_rom_threshold = st.slider("æœ€å°è¡Œç¨‹ (Min ROM, m)", 0.05, 0.80, 0.15, step=0.05, help="éæ¿¾æ‰è¡Œç¨‹éçŸ­çš„èª¤åˆ¤ (ä¾‹å¦‚è‡¥æ¨å»ºè­° 0.15, æ·±è¹² 0.30)")

    # è®€å–åˆ†æèµ·å§‹å¹€ (ç”¨æ–¼ç•«æ¡†)
    cap.set(cv2.CAP_PROP_POS_MSEC, start_t * 1000)
    ret, first_frame = cap.read()
    
    if ret:
        if rotation_code is not None:
            first_frame = cv2.rotate(first_frame, rotation_code)

        h_orig, w_orig = first_frame.shape[:2]
        
        # --- 3. æ ¡å‡†èˆ‡è¿½è¹¤è¨­å®š (Canvas) ---
        st.header("3. æ ¡æº–èˆ‡ç›®æ¨™è¨­å®š")
        
        # --- Mobile Optimization (Moved to Global Settings) ---
        # is_mobile definition moved to top
        
        if is_mobile:
            max_canvas_width = 300 # Reduced to 300 to fit smaller screens (iPhone SE is 320px)
            max_canvas_height = 500
        else:
            max_canvas_width = 800
            max_canvas_height = 600

        # Instructions in expander
        with st.expander("ğŸ‘‰ ç¹ªåœ–æ“ä½œèªªæ˜ (æŒ‰æ­¤å±•é–‹)", expanded=not is_mobile):
             st.info("ğŸ‘‡ æ“ä½œèªªæ˜")
             st.markdown("è«‹åœ¨ä¸‹æ–¹åœ–ç‰‡ä¸Šä¾åºç•«æ¡† (ç´… -> ç¶ )ï¼š")
             st.markdown("1. **ç´…è‰²æ¡†**: æ ¡æº–æ§“ç‰‡")
             st.markdown("2. **ç¶ è‰²æ¡†**: è¿½è¹¤ç›®æ¨™")
             if is_mobile:
                 st.markdown("---")
                 st.warning("ğŸ“± **æ‰‹æ©Ÿæ“ä½œæç¤º**:")
                 st.markdown("- **å–®æŒ‡ (One Finger)**: ç•«æ¡† (è«‹ç”¨åŠ›æŒ‰å£“ä¸¦æ‹–æ›³)")
                 st.markdown("- **é›™æŒ‡ (Two Fingers)**: æ²å‹•é é¢")
                 st.markdown("- è‹¥ç„¡æ³•ç•«åœ–ï¼Œè«‹ç¢ºä¿ç¶²é æ²’æœ‰æ”¾å¤§ç¸®å°")

        from streamlit_drawable_canvas import st_canvas
        from PIL import Image

        # ç¸®æ”¾åœ–ç‰‡ä»¥é©æ‡‰ç•«å¸ƒ
        h_orig, w_orig = first_frame.shape[:2]
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
        scale_w = max_canvas_width / w_orig
        scale_h = max_canvas_height / h_orig
        canvas_scale = min(1.0, scale_w, scale_h)
        
        display_w = int(w_orig * canvas_scale)
        display_h = int(h_orig * canvas_scale)
        
        frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
        frame_pil = Image.fromarray(frame_rgb).resize((display_w, display_h))
        
        if "stroke_color" not in st.session_state:
            st.session_state.stroke_color = "#FF0000"

        # --- Inline Canvas (Pre-defined Boxes for Mobile Ease) ---
        st.markdown("##### æ­¥é©Ÿ 3.1: èª¿æ•´æ¡†çš„ä½ç½®")
        st.info("ğŸ‘† ç›´æ¥æ‹–æ›³æ¡†åˆ°æ­£ç¢ºä½ç½®ã€‚ **ç´…è‰²=æ§“ç‰‡** (æ ¡æº–ç”¨), **ç¶ è‰²=è¿½è¹¤ç›®æ¨™**")
        
        # Initial Drawing Objects (Fabric.js JSON format)
        if "initial_drawing" not in st.session_state:
            # Default positions: consistent logic regardless of image size, but use absolute pixels
            # Plate (Red) top-leftish, Target (Green) centerish
            st.session_state.initial_drawing = {
                "version": "4.4.0",
                "objects": [
                    {
                        "type": "rect",
                        "left": int(display_w * 0.1),
                        "top": int(display_h * 0.8),
                        "width": 100,
                        "height": 100,
                        "fill": "rgba(255, 0, 0, 0.2)",
                        "stroke": "#FF0000",
                        "strokeWidth": 3
                    },
                    {
                        "type": "rect",
                        "left": int(display_w * 0.4),
                        "top": int(display_h * 0.3),
                        "width": 100,
                        "height": 100,
                        "fill": "rgba(0, 255, 0, 0.2)",
                        "stroke": "#00FF00",
                        "strokeWidth": 3
                    }
                ]
            }

        # Canvas
        # Use a dynamic key based on filename to force full component remount when video changes
        # This prevents the "Missing file" error caused by the canvas trying to load the old background image
        canvas_key = f"canvas_{st.session_state.last_uploaded}"
        
        c_result = st_canvas(
            fill_color="rgba(255, 165, 0, 0.1)",
            stroke_width=3,
            background_image=frame_pil,
            update_streamlit=True,
            height=display_h,
            width=display_w,
            drawing_mode="transform", # Only allow moving/resizing
            initial_drawing=st.session_state.initial_drawing,
            key=canvas_key,
            display_toolbar=False, # Hide toolbar
        )
        
        # Process Canvas Result & Color Logic
        plate_rect = None
        target_rect = None
        
        if c_result.json_data is not None:
            objects = c_result.json_data["objects"]
            
            # Identify by color
            for obj in objects:
                color = obj.get("stroke", "").upper()
                left = int(obj["left"] / canvas_scale)
                top = int(obj["top"] / canvas_scale)
                w = int(obj["width"] * obj.get("scaleX", 1) / canvas_scale)
                h = int(obj["height"] * obj.get("scaleY", 1) / canvas_scale)
                
                rect = (left, top, w, h)
                
                if color == "#FF0000":
                    plate_rect = rect
                elif color == "#00FF00":
                    target_rect = rect

            if plate_rect and target_rect:
                st.success(f"âœ… è¨­å®šå®Œæˆ! æ§“ç‰‡: {plate_rect}, ç›®æ¨™: {target_rect}")
            else:
                 # Should theoretically not happen unless they delete it (which is hard without toolbar)
                 st.warning("âš ï¸ æª¢æ¸¬ä¸åˆ°æ¡†ï¼Œè«‹é‡æ–°æ•´ç†ç¶²é ")

        # --- 4. åŸ·è¡Œåˆ†æ ---
        st.markdown("###")
        btn_disabled = (plate_rect is None or target_rect is None)
        
        if st.button("ğŸš€ é–‹å§‹æ™ºèƒ½åˆ†æ (Start Analysis)", type="primary", disabled=btn_disabled):
            if btn_disabled:
                st.error("è«‹å…ˆå®Œæˆæ ¡æº–ç‰©èˆ‡ç›®æ¨™çš„æ¡†é¸ï¼")
                st.stop()
            
            # --- åˆå§‹åŒ–æ•¸æ“š ---
            st.write("æ­£åœ¨è™•ç†å½±åƒ... (é€™å¯èƒ½éœ€è¦å¹¾ç§’é˜)")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ä½¿ç”¨æˆ‘å€‘å¾ Canvas æ‹¿åˆ°çš„åº§æ¨™ï¼Œè€Œä¸æ˜¯ Sliders
            (plate_x, plate_y, plate_w, plate_h) = plate_rect
            # Plate Size ç”¨å¯¬åº¦æˆ–é«˜åº¦çš„å¹³å‡ï¼Œæˆ–åŸæœ¬é‚è¼¯
            # åœ¨åŸ logic ä¸­ plate_s åªæœ‰ä¸€å€‹ç¶­åº¦ï¼Œé€™è£¡æˆ‘å€‘å–æœ€å¤§é‚Šä½œç‚ºç›´å¾‘ä¼°è¨ˆ
            plate_s = max(plate_w, plate_h) 
            
            (bar_x, bar_y, bar_w, bar_h) = target_rect

            # 1. è¨­ç½® Tracker
            # 2. å„ªåŒ–: è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ (Process Scale) ä»¥åŠ é€Ÿè™•ç†
            target_width = 640  # é™åˆ¶è™•ç†å¯¬åº¦ç‚º 640pxï¼Œå¤§å¹…æå‡ç¶²é ç«¯é€Ÿåº¦
            process_scale = target_width / float(w_orig)
            
            # ä¾æ¯”ä¾‹ç¸®å° ROI
            roi_track_small = (int(bar_x * process_scale),
                               int(bar_y * process_scale),
                               int(bar_w * process_scale),
                               int(bar_h * process_scale))
            
            # ä¾æ¯”ä¾‹ç¸®å°ç¬¬ä¸€å¹€ä¸¦åˆå§‹åŒ–
            first_frame_small = cv2.resize(first_frame, (0,0), fx=process_scale, fy=process_scale)
            
            # --- å¢å¼·è¿½è¹¤: ç°éš + CLAHE (åƒè€ƒ Local Logic) ---
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            first_frame_gray = cv2.cvtColor(first_frame_small, cv2.COLOR_BGR2GRAY)
            first_frame_enhanced = clahe.apply(first_frame_gray)
            
            tracker = cv2.TrackerCSRT_create()
            tracker.init(first_frame_enhanced, roi_track_small)
            
            # è¨ˆç®—çœŸå¯¦ä¸–ç•Œæ¯”ä¾‹å°º (Meters per Pixel)
            # å‡è¨­æ¨™æº–ç‰‡ç›´å¾‘ 0.45 ç±³ (45cm)
            meters_per_pixel = 0.45 / float(plate_s) 
            
            positions = []
            times = []
            
            start_frame = int(start_t * fps)
            curr_frame_idx = start_frame
            end_frame_idx = int(end_t * fps)
            total_frames = end_frame_idx - start_frame
            
            # --- åˆ†æè¿´åœˆ ---
            # --- åˆ†æè¿´åœˆ (Optimized with Threading) ---
            # Start the threaded video reader
            video_reader = ThreadedVideoReader(video_path, start_frame, end_frame_idx, process_scale, rotation_code)
            video_reader.start()
            
            while video_reader.more():
                item = video_reader.read()
                if item is None:
                    break
                    
                (ret, frame_small, idx) = item
                if not ret:
                    break
                
                # Performance Optimization: Frame Skipping
                current_process_idx = idx - start_frame
                
                # Default assume success for skipped frames (we will interpolate later)
                # But for tracking, we only update tracker on specific frames
                
                if current_process_idx == 0 or current_process_idx % (frame_skip + 1) == 0:
                    # --- å¢å¼·è¿½è¹¤: ç°éš + CLAHE ---
                    frame_gray = cv2.cvtColor(frame_small, cv2.COLOR_BGR2GRAY)
                    frame_enhanced = clahe.apply(frame_gray)
                    
                    success, box = tracker.update(frame_enhanced)
                    
                    if success:
                        (x, y, bw, bh) = [int(v) for v in box]
                        cy_small = y + bh/2
                        cy_original = cy_small / process_scale
                        
                        positions.append(cy_original)
                        times.append(idx / fps)
                
                # æ›´æ–°é€²åº¦æ¢ (æ¯ 10 å¹€æ›´æ–°ä¸€æ¬¡ä»¥ç¯€çœè³‡æº)
                if total_frames > 0 and idx % 10 == 0:
                    prog = (idx - start_frame) / total_frames
                    progress_bar.progress(min(prog, 1.0))
            
            progress_bar.progress(1.0)
            video_reader.stop()
            
            # --- 5. æ•¸æ“šå¾Œè™•ç† (Data Post-Processing - SYNCED WITH DESKTOP) ---
            if len(positions) > 10:
                # === REPLACED: Updated with Physics-Based Kalman Filter ===
                
                # 1. æ•¸æ“šé è™•ç† (åƒç´  -> å…¬å°º)
                # åŸå§‹ positions (cy_original) æ˜¯å‘ä¸‹å¢åŠ ï¼Œæ‰€ä»¥æˆ‘å€‘å–è² è™Ÿè®“ã€Œå‘ä¸Šã€ç‚ºæ­£
                raw_y_meters = [(-y * meters_per_pixel) for y in positions]
                
                # 2. åˆå§‹åŒ–å¡çˆ¾æ›¼æ¿¾æ³¢å™¨
                # åƒæ•¸ç›´æ¥å°é½Š Desktop ç‰ˆ: Process Noise=150.0, Meas Noise=0.1
                kf = SimpleKalmanFilter(
                    initial_value=raw_y_meters[0], 
                    process_noise=150.0, 
                    measurement_noise=0.1 
                )
                
                kalman_pos = []
                kalman_vel = []
                t_clean = []
                
                for i in range(len(raw_y_meters)):
                    current_time = times[i]
                    meas = raw_y_meters[i]
                    
                    if i == 0:
                        dt = 0
                    else:
                        dt = current_time - times[i-1]
                    
                    # éæ¿¾æ‰ç•°å¸¸çš„æ™‚é–“å·® (ä¾‹å¦‚æ‰å¹€)
                    if dt > 1.0: dt = 1.0/fps
                    
                    k_pos, k_vel = kf.process(meas, dt)
                    
                    kalman_pos.append(k_pos)
                    kalman_vel.append(k_vel)
                    t_clean.append(current_time)

                # è½‰æ›ç‚º numpy array ä»¥ä¾¿å¾ŒçºŒè™•ç†
                # ä½ç½®æˆ‘å€‘ç”¨ç›¸å°ä½ç§» (å¾ 0 é–‹å§‹)
                y_smooth = np.array(kalman_pos)
                y_smooth = y_smooth - y_smooth[0] 
                
                # å¡çˆ¾æ›¼ç›´æ¥çµ¦å‡ºé€Ÿåº¦ï¼Œç„¡éœ€å†å¾®åˆ†
                velocity_smooth = np.array(kalman_vel)
                time_array = np.array(t_clean)
                
                # 3. REP DETECTION LOGIC (State Machine & VBT Metrics)
                
                # å…ˆè¨ˆç®—åŠ é€Ÿåº¦ (Acceleration) ç”¨æ–¼ MPV
                # a = dv/dt
                acceleration = np.gradient(velocity_smooth, time_array)
                
                reps = []
                
                # --- åƒæ•¸è¨­å®š (Config) ---
                MIN_VEL_THRESH = 0.05       
                MIN_DUR_SEC = 0.05          
                MIN_DUR_FRAMES = int(MIN_DUR_SEC * fps) 
                
                # [FIX 1] å°‡ 0.15 æ”¹ç‚º 0.05 (5å…¬åˆ†)
                MIN_ROM_METERS = 0.05       
                
                GRAVITY = 9.81              

                in_concentric = False
                start_idx = 0
                
                for i in range(len(velocity_smooth) - MIN_DUR_FRAMES):
                    v = velocity_smooth[i]
                    
                    if not in_concentric:
                        # --- START TRIGGER ---
                        if v > MIN_VEL_THRESH:
                            # é è®€æ¥ä¸‹ä¾†å¹¾å¹€
                            future_window = velocity_smooth[i : i + MIN_DUR_FRAMES]
                            
                            # [FIX 2] å°‡ np.min æ”¹ç‚º np.mean (å®¹è¨±å¾®å°æŠ–å‹•)
                            if np.mean(future_window) > MIN_VEL_THRESH:
                                in_concentric = True
                                start_idx = i
                                
                    else:
                        # --- END TRIGGER ---
                        # æ¢ä»¶ï¼šé€Ÿåº¦ < 0 (é–‹å§‹ä¸‹æ”¾) æˆ– æ•¸æ“šçµæŸ
                        if v < 0 or i == len(velocity_smooth) - MIN_DUR_FRAMES - 1:
                            in_concentric = False
                            end_idx = i
                            
                            # --- æ•¸æ“šåˆ‡ç‰‡ (Slicing) ---
                            vel_slice = velocity_smooth[start_idx : end_idx]
                            acc_slice = acceleration[start_idx : end_idx]
                            pos_slice = y_smooth[start_idx : end_idx]
                            t_slice = time_array[start_idx : end_idx]
                            
                            # --- VALIDATION (éæ¿¾ç„¡æ•ˆæ¬¡æ•¸) ---
                            
                            # 1. ROM æª¢æŸ¥ (ä½ç§»é‡)
                            rep_rom = pos_slice[-1] - pos_slice[0]
                            if rep_rom < MIN_ROM_METERS:
                                continue # è·³éé€™æ¬¡èª¤åˆ¤
                                
                            # --- METRICS CALCULATION (è¨ˆç®— MV & MPV) ---
                            
                            # A. Mean Velocity (MV) - æ•´å€‹å‘å¿ƒéšæ®µ
                            mv = np.mean(vel_slice)
                            
                            # B. Mean Propulsive Velocity (MPV)
                            # æ¢ä»¶ï¼šåŠ é€Ÿåº¦ >= -9.81 m/s^2 (ä»£è¡¨é‹å‹•å“¡æ­£åœ¨æ–½åŠ›å°æŠ—é‡åŠ›)
                            propulsive_mask = acc_slice >= -GRAVITY
                            if np.any(propulsive_mask):
                                mpv = np.mean(vel_slice[propulsive_mask])
                            else:
                                mpv = mv # ç•°å¸¸ä¿è­·
                            
                            peak_v = np.max(vel_slice)
                            peak_local_idx = np.argmax(vel_slice)
                            peak_time = t_slice[peak_local_idx]
                            
                            reps.append({
                                'start_idx': start_idx,
                                'end_idx': end_idx,
                                'mv': mv,
                                'mpv': mpv,
                                'peak_v': peak_v,
                                'peak_t': peak_time,
                                'rom': rep_rom
                            })

                num_reps = len(reps)
                
                # --- RESULTS AGGREGATION ---
                mv_list = [r['mv'] for r in reps]
                mpv_list = [r['mpv'] for r in reps]
                
                # è¨ˆç®—å„è‡ªçš„ã€Œæ•´çµ„å¹³å‡å€¼ã€ (Set Average)
                avg_mv = float(np.mean(mv_list)) if mv_list else 0.0
                avg_mpv = float(np.mean(mpv_list)) if mpv_list else 0.0 # Renamed to match downstream
                
                # è¨ˆç®—æœ€ä½³å€¼èˆ‡ç–²å‹ (ä»¥ MPV ç‚ºåŸºæº–)
                best_mpv = max(mpv_list) if mpv_list else 0.0
                worst_mpv = min(mpv_list) if mpv_list else 0.0
                
                loss_pct = 0.0
                slowest_rep_num = 0
                
                if mpv_list:
                    # æ‰¾å‡ºæœ€æ…¢çš„ä¸€ä¸‹ (åŸºæ–¼ MPV)
                    slowest_idx = mpv_list.index(worst_mpv)
                    # è¨ˆç®—ç–²å‹æµå¤±ç‡
                    loss_pct = ((best_mpv - worst_mpv) / best_mpv) * 100
                
                # For compatibility with plotting code below
                height_smooth = y_smooth 
                
                # Drop calculations - keeping original UI variable name 'biggest_drop_pct' for display logic below
                biggest_drop_pct = loss_pct
                drop_reps_indices = (-1, -1) # Disable the old pair-wise drop logic for now or mapped to fatigue
                
                # --- 6. çµæœå±•ç¤º ---
                st.success(f"åˆ†æå®Œæˆï¼åµæ¸¬åˆ° {num_reps} çµ„å‹•ä½œ (Reps)")
                
                # çµ±è¨ˆæ•¸æ“šå¡ç‰‡ (Result Metrics - Desktop Style)
                c1, c2, c3 = st.columns(3)
                c1.metric("Best MPV", f"{best_mpv:.2f} m/s", delta=f"Avg: {avg_mpv:.2f}")
                c2.metric("Set Avg MV", f"{avg_mv:.2f} m/s")
                
                loss_label = "Fatigue (Loss%)"
                if fastest_rep_idx := locals().get('slowest_rep', None): # Not defined here actually
                    pass 
                
                c3.metric(loss_label, f"{loss_pct:.1f}%", delta_color="inverse" if loss_pct > 10 else "normal")

                # --- ç¹ªåœ– (Matplotlib) ---
                # --- ç¹ªåœ– (Matplotlib) - PRO Style ---
                # ä½¿ç”¨ Dark Background é¢¨æ ¼
                plt.style.use('dark_background')
                
                # Create Figure with specific bg color to match Streamlit dark theme approximation
                fig, ax = plt.subplots(figsize=(10, 5))
                fig.patch.set_facecolor('#0e1117') # Match Streamlit dark bg
                ax.set_facecolor('#0e1117')
                
                # 1. ç¹ªè£½ã€ŒèƒŒæ™¯ã€åº•å±¤æ›²ç·š (Raw Velocity)
                ax.plot(time_array, velocity_smooth, color='#444444', linewidth=1.0, alpha=0.6, label='Raw Velocity')
                
                # 2. ç¹ªè£½ã€Œæœ‰æ•ˆå‘å¿ƒéšæ®µã€
                max_v_limit = 0
                
                for i, r in enumerate(reps):
                    rep_num = i + 1
                    t_s_idx = r['start_idx']
                    t_e_idx = r['end_idx']
                    
                    t_segment = time_array[t_s_idx : t_e_idx+1]
                    v_segment = velocity_smooth[t_s_idx : t_e_idx+1]
                    
                    if len(t_segment) > 0:
                        # Plot Rep Segment
                        ax.plot(t_segment, v_segment, color='#00e5ff', linewidth=2.5)
                        # Fill Area
                        ax.fill_between(t_segment, v_segment, 0, color='#00e5ff', alpha=0.2)
                        
                        # Annotations
                        display_val = r['mpv'] # Priority: MPV
                        peak_time = r['peak_t']
                        peak_val = r['peak_v']
                        
                        label_text = f"#{rep_num}\n{display_val:.2f}"
                        
                        ax.annotate(
                            label_text, 
                            xy=(peak_time, peak_val), 
                            xytext=(0, 20), 
                            textcoords='offset points', 
                            ha='center', va='bottom',
                            fontsize=9, fontweight='bold', color='#ffffff',
                            bbox=dict(boxstyle="round,pad=0.3", fc="#262730", ec="#00e5ff", alpha=0.9)
                        )
                        
                        max_v_limit = max(max_v_limit, peak_val)
                        
                # 3. è¼”åŠ©ç·šèˆ‡ç¶²æ ¼
                ax.axhline(0, color='#666666', linewidth=1, linestyle='--')
                
                # Axis Styling
                ax.set_xlabel('Time (s)', color='#fafafa', fontsize=10)
                ax.set_ylabel('Velocity (m/s)', color='#00e5ff', fontweight='bold', fontsize=10)
                
                ax.tick_params(axis='x', colors='#fafafa')
                ax.tick_params(axis='y', colors='#fafafa')
                
                # Hide Spines
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                ax.spines['bottom'].set_color('#444444')
                ax.spines['left'].set_color('#444444')
                
                ax.grid(True, which='major', axis='y', alpha=0.1, color="#ffffff", linestyle=':')
                
                if max_v_limit > 0:
                    ax.set_ylim(top=max_v_limit * 1.3) # Leave space for annotations
                
                st.pyplot(fig)
                
                # --- ä¸‹è¼‰æ•¸æ“š ---
                # Build detailed rep table
                rep_data = []
                for i, r in enumerate(reps):
                    rep_data.append({
                        "Rep": i+1,
                        "Mean Velocity (m/s)": round(r['mv'], 3),
                        "Mean Propulsive V (m/s)": round(r['mpv'], 3),
                        "Peak Velocity (m/s)": round(r['peak_v'], 3),
                        "ROM (m)": round(r['rom'], 3),
                        "Duration (s)": round(time_array[r['end_idx']] - time_array[r['start_idx']], 3)
                    })
                
                st.write("### è©³ç´°æ•¸æ“š (Detailed Data)")
                st.dataframe(pd.DataFrame(rep_data))
                
                df = pd.DataFrame({
                    "Time": time_array, 
                    "Velocity": velocity_smooth, 
                    "Acceleration": acceleration,
                    "Height": height_smooth
                })
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Raw CSV æ•¸æ“š", csv, "barbell_analysis_raw.csv", "text/csv")
                
            else:
                st.error("âŒ è¿½è¹¤å¤±æ•—æˆ–æ•¸æ“šå¤ªçŸ­ã€‚è«‹å˜—è©¦ï¼š\n1. èª¿æ•´ç¶ è‰²è¿½è¹¤æ¡†çš„ä½ç½®\n2. ç¢ºä¿å½±ç‰‡å…‰ç·šå……è¶³ä¸”èƒŒæ™¯å–®ç´”")

    else:
        st.error("ç„¡æ³•è®€å–å½±ç‰‡å¹€ï¼Œè«‹æª¢æŸ¥å½±ç‰‡æ ¼å¼ã€‚")